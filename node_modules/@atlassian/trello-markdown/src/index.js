/*
 * decaffeinate suggestions:
 * DS101: Remove unnecessary use of Array.from
 * DS102: Remove unnecessary code created because of implicit returns
 * DS201: Simplify complex destructure assignments
 * DS205: Consider reworking code to avoid use of IIFEs
 * DS206: Consider reworking classes to avoid initClass
 * DS207: Consider shorter variations of null checks
 * Full docs: https://github.com/decaffeinate/decaffeinate/blob/master/docs/suggestions.md
 */

/**
 * Rough approximation of _.intersection, returns an array of values that are
 * present in both of the input arrays
 */
const intersection = (arr1, arr2) => {
  return arr1.reduce((accum, item) => {
    if (arr2.includes(item)) {
      accum.push(item);
    }

    return accum;
  }, []);
};

/**
 * Rough approximation of _.pick, returns a copy of the input object with only
 * properties specified by the `keys` array
 */
const pick = (obj, keys) => {
  return Object.keys(obj).reduce((accum, key) => {
    if (keys.includes(key)) {
      accum[key] = obj[key];
    }

    return accum;
  }, {});
};

/*
Adapted from https://github.com/chjj/marked/blob/master/lib/marked.js

Step 1 - Block Lexing

Take the plain text, and do "Block Lexing", breaking it up into tokens that
represent paragraphs, lists, headings, etc.  This is also the stage where we
figure out [1]: ... style link references.  Some of these blocks will have text
that needs further processing, for these we do "inline lexing".

Step 2 - Inline Lexing

Convert the text part of a block token into inline tokens.  This is where we'd
generate tokens that represent bold, italic, links, etc.

(After this step we've created a list of the locations of the locations in our
original string that match the different rules)

Step 3 - Block Parsing

Here we output the HTML representation of the block tokens.  Some of the blocks
will children (aka inline formatting)

Step 4 - Inline Parsing

Here we output the HTML representation of the inline tokens.

Notes:

  - The Block Lexing/Parsing and Inline Lexing/Parsing are very similar.  The
    lexer rules (i.e. lexerBlockRules and lexerInlineRules) contain patterns
    of text that should be converted to a token and a method that converts
    the regex capture into a token.

    For example:

    code:
      match: ///
        ^
        (
          \x20{4} # 4 spaces
          [^\n]+
          \n*
        )+
      ///
      token: ([ all ]) ->
        type: 'code'
        text: all.replace(/^ {4}/gm, '').replace(/\n+$/, '')

    ... says that a group of lines that start with 4 spaces is considered a
    match, and the token function takes the capture, and generates a token of
    type 'code'.

    The "token" functions can return

     - a single token
     - an array of tokens
     - null (no tokens)
     - false (there was a match, but we've decided to ignore that fact and
       continue trying other rules)

    All tokens have a "type" attribute, that indicates which outputter to
    use; the outputters (i.e. parseBlockRules and parseInlineRules) convert the
    tokens to HTML.  (They take the token as an argument)

    For example:

    code: ({ text }) ->
      @htmln('code', @text(text), { preTag: '<pre>', postTag: '</pre>' })

    ... takes a token with type "code", and outputs a <code> tag that contains
    the text part of the token rendered as text.  (Additionally, it puts a
    <pre> tag before and a </pre> after)

  - The order of the entries in lexerBlockRules and lexerInlineRules are
    important; e.g. you'd certainly want to figure out the code blocks before
    you tried to detect other types of formatting.  There should always be
    a match; if we get to the last rule, we throw.

  - Remember, the . behaves differently in Javascript; /./.test("\n") == false
    That's why you'll see [\s\S] being used

  - Because we've expanded many of the regexs out using ///, we can't use / +/
    to mean "an arbitrary number of space characters"
    That's why you'll see \x20* being used

*/

var TrelloMarkdown = (function () {
  let _linkToken = undefined;
  let parseAtMention = undefined;
  let _prepareText = undefined;
  TrelloMarkdown = class TrelloMarkdown {
    static initClass() {
      this.lexerBlockRules = {
        newline: {
          match: /^\n/,
          token(...args) {
            // Won't actually result in any output, it's just to separate paragraphs
            const [all] = Array.from(args[0]),
              ranges = args[2];
            return {
              type: 'space',
              canCondense: true,
              children: { text: all, ranges: ranges.slice(0, all) },
            };
          },
        },

        /*
            for i in [0..10]
              console.log(i)
        */
        code: {
          match: new RegExp(`\
^\
(\
\\x20{4}\
[^\\n]+\
\\n*\
)+\
`),
          token(...args) {
            const [all] = Array.from(args[0]);
            return {
              type: 'code',
              text: all.replace(/^ {4}/gm, '').replace(/\n+$/, ''),
            };
          },
        },

        /*
        A Github Flavored Markdown feature
        ````
        for i in [0..10]
          console.log(i)
        ````
        */
        fencedCode: {
          match: new RegExp(`\
^\
\\x20*\
(\`{3,}|~{3,})\
\\x20*\
(\\S+)?\
\\x20*\
\\n\
([\\s\\S]+?)\
\\s*?\
\\1\
\\x20*\
(?:\\n+|$)\
`),
          token(...args) {
            const [, , language, text] = Array.from(args[0]);
            return {
              type: 'code',
              language,
              text,
            };
          },
        },

        /*

         *# Heading ##

         */ //
        heading: {
          match: new RegExp(`\
^\
(\
\\x20*\
(\\#{2,6}|\\#(?![a-fA-F0-9]{6}(?:\\s|$)))\
\\x20*\
)\
([^\\n]+?)\
\\x20*\
\\#*\
\\x20*\
(?:\\n+|$)\
`),
          token(...args) {
            const [, beforeText, depth, text] = Array.from(args[0]),
              ranges = args[2];
            return {
              type: 'heading',
              depth: depth.length,
              children: { text, ranges: ranges.slice(beforeText.length, text) },
            };
          },
        },

        /*
        Heading
        -------
        */
        lheading: {
          match: new RegExp(`\
^\
([^\\n]+)\
\\n\
\\x20*\
(=|-){3,}\
\\x20*\
\\n*\
`),
          token(...args) {
            const [, text, char] = Array.from(args[0]),
              ranges = args[2];
            return {
              type: 'heading',
              depth: char === '=' ? 1 : 2,
              children: { text, ranges: ranges.slice(0, text) },
            };
          },
        },

        /*
        ----------
        * * * * * *
        __________
        */
        hr: {
          match: new RegExp(`\
^\
(?:\\x20*[-*_]){3,}\
\\x20*\
(?:\\n|$)\
`),
          token() {
            return { type: 'hr' };
          },
        },

        /*
        > Some quote
        > more quote
        even more quote
        */
        blockquote: {
          match: new RegExp(`\
^\
(\
\\x20*\
>\
[^\\n]+\
(\
\\n\
[^\\n]+\
)*\
\\n*\
)+\
`),
          token(...args) {
            // Remove all of the > for the blockquote, and also remove those sections
            // from our ranges
            const [all] = Array.from(args[0]),
              state = args[1],
              ranges = args[2];
            const subtractSpans = [];
            const quote = all.replace(/^ *> ?/gm, function (match, index) {
              for (let span of Array.from(ranges.slice(index, match).spans)) {
                subtractSpans.push(span);
              }
              return '';
            });

            const blockquoteRanges = ranges.subtract(
              new SelectionRange(subtractSpans),
            );

            return [
              { type: 'blockquote_start' },
              ...Array.from(this.blockLex(quote, state, blockquoteRanges)),
              { type: 'blockquote_end' },
            ];
          },
        },

        /*
        - item 1
        - item 2
        */
        num: {
          match: new RegExp(`\
(?:\
\\d+\\.\
)\
`),
        },

        dash: {
          match: new RegExp(`\
(?:\
[*+-]\
)\
`),
        },

        bullet: {
          match: new RegExp(`\
(?:\
dash\
|\
num\
)\
`),
        },

        item: {
          match: new RegExp(`\
^\
(\\x20*)\
(bullet)\
\\x20\
[^\\n]*\
(?:\
\\n\
(?!\
\\1\
bullet\
\\x20\
)\
[^\\n]*\
)*\
`),
        },

        list: {
          match: new RegExp(`\
^\
(\\x20*)\
\
\
(?:\
(dash)\
\\x20\
[\\s\\S]+?\
(?:\
\\nhr\
|\
\\n{2,}(?=def|(?!\\x20))(?!\\1dash\\x20)\\n*\
|\
\\s*$\
)\
\
|\
\
(num)\
\\x20\
[\\s\\S]+?\
(?:\
\\nhr\
|\
\\n{2,}(?=def|(?!\\x20))(?!\\1num\\x20)\\n*\
|\
\\s*$\
)\
)\
`),
          token(...args) {
            const [all, , dash_bullet] = Array.from(args[0]),
              state = args[1],
              ranges = args[2];
            let next = false;
            let index = 0;
            const itemsTokens = [];
            const tag = dash_bullet != null ? 'ul' : 'ol';

            // We have to do all the matches once before we process them, so we
            // handle the last one correctly
            const itemCount = all.match(
              this.lexerBlockRules.item.match_gim,
            ).length;

            // We're doing a replace because it's a convenient way to get the
            // locations of all of the matches
            all.replace(
              this.lexerBlockRules.item.match_gim,
              (item, ...rest) => {
                let adjustedLength, itemIndex;
                (adjustedLength = Math.max(rest.length, 2)),
                  (itemIndex = rest[adjustedLength - 2]);
                let itemRanges = ranges.slice(itemIndex, item);

                // Determine whether item is "loose" or not.
                // Loose lists have newlines between the list items, list this:
                //
                // 1. Foo
                //
                // 2. Bar
                //
                let loose = next || /\n\n(?!\s*$)/.test(item);
                if (index !== itemCount - 1) {
                  next = item[item.length - 1] === '\n';
                  if (!loose) {
                    loose = next;
                  }
                }

                let space = item.length;
                // Drop the bullet
                item = item.replace(
                  new RegExp(`^\\x20*([*+-]|\\d+\\.)\\x20+`),
                  function (all) {
                    itemRanges = itemRanges.subtract(itemRanges.slice(0, all));
                    return '';
                  },
                );
                space -= item.length;

                // Outdent the list contents
                //
                // - Foo bar
                //   baz
                //
                // becomes
                //
                // Foo bar
                // baz
                const itemRangesOrig = itemRanges.clone();
                item = item.replace(
                  new RegExp(`^\\x20{1,${space}}`, 'gm'),
                  function (match, index) {
                    itemRanges = itemRanges.subtract(
                      itemRangesOrig.slice(index, match),
                    );
                    return '';
                  },
                );

                itemsTokens.push([
                  { type: 'list_item_start', tag, condense: !loose, index },
                  ...Array.from(
                    this.blockLex(
                      item,
                      this._disallow(state, 'top'),
                      itemRanges,
                    ),
                  ),
                  { type: 'list_item_end' },
                ]);

                index++;
                return '';
              },
            );

            return [
              { type: 'list_start', tag },
              ...Array.from(itemsTokens.flat()),
              { type: 'list_end' },
            ];
          },
        },

        /*
        trello [1] bar [2]

        [1]: http://trello.com
        [2]: <https://fogcreek.com> "Fog Creek Software"
        */
        def: {
          whenAllowed: 'top',
          match: new RegExp(`\
^\
\\x20*\
\\[\
([^\\]]+)\
\\]:\
\\x20*\
<?\
([^\\s>]+)\
>?\
(?:\\x20+["(]([^\\n]+)[")])?\
\\x20*\
(?:\\n+|$)\
`),
          token(...args) {
            const [, ref, url, title] = Array.from(args[0]),
              { references } = args[1];
            if (references != null) {
              references.set(ref, { url, title });
            }
            return null;
          },
        }, // We handled the input, but we didn't create any tokens

        blockAtMention: {
          nondefault: true,
          match: new RegExp(`\
^\
@\
([a-z0-9_]+)\
(?=\\n|$)\
`),
          token(...args) {
            const [, username] = Array.from(args[0]);
            return {
              type: 'atMention',
              username,
            };
          },
        },

        paragraph: {
          whenAllowed: 'top',
          match: new RegExp(`\
^\
(\
(?:\
[^\\n]+\
\\n?\
(?!\
hr|heading|lheading|blockquote|def|blockAtMention\
)\
)+\
)\
\\n*\
`),
          token(...args) {
            const [, content] = Array.from(args[0]),
              ranges = args[2];
            const text = content.replace(/\n$/, '');
            return {
              type: 'text',
              children: { text, ranges: ranges.slice(0, text) },
            };
          },
        },

        text: {
          required: true,
          match: new RegExp(`\
^[^\\n]+\
`),
          token(...args) {
            const [all] = Array.from(args[0]),
              ranges = args[2];
            return {
              type: 'text',
              canCondense: true,
              children: { text: all, ranges: ranges.slice(0, all) },
            };
          },
        },

        error: {
          required: true,
          match: /^[\s\S]+/,
          token(...args) {
            const [all] = Array.from(args[0]);
            throw Error(`invalid block input ${all}`);
          },
        },
      };

      _linkToken = function ({ image, text, url, title, ranges }) {
        const token = { title, url };
        if (image) {
          token.type = 'image';
          token.text = text;
        } else {
          token.type = 'link';
          token.children = { text, ranges: ranges.slice(1, text) };
        }
        return token;
      };

      this.lexerInlineRules = {
        escape: {
          required: true,
          match: new RegExp(`^\\\\([\\\\\`*{}\\[\\]()\\#+\\-.!_>~|@:])`),
          token(...args) {
            const [, escaped] = Array.from(args[0]);
            return {
              type: 'text',
              text: escaped,
            };
          },
        },

        tld: {
          match: new RegExp(`\
(?:\
\
\
ac|ad|aero|ae|af|ag|ai|al|am|an|ao|aq|arpa|ar|asia|as|at|au|aw|ax|az|\
ba|bb|bd|be|bf|bg|bh|biz|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|\
cat|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|coop|com|co|cr|cu|cv|cx|cy|cz|\
de|dj|dk|dm|do|dz|\
ec|edu|ee|eg|er|es|et|eu|\
fi|fj|fk|fm|fo|fr|\
ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gov|gp|gq|gr|gs|gt|gu|gw|gy|\
hk|hm|hn|hr|ht|hu|\
id|ie|il|im|info|int|in|io|iq|ir|is|it|\
je|jm|jobs|jo|jp|\
ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|\
la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|\
ma|mc|md|me|mg|mh|mil|mk|ml|mm|mn|mobi|mo|mp|mq|mr|ms|mt|museum|mu|mv|\
mw|mx|my|mz|\
name|na|nc|net|ne|nf|ng|ni|nl|no|np|nr|nu|nz|\
om|org|\
pa|pe|pf|pg|ph|pk|pl|pm|pn|pro|pr|ps|pt|pw|py|\
qa|\
re|ro|rs|ru|rw|\
sa|sb|sc|sd|se|sg|sh|si|sj|sk|sl|sm|sn|so|sr|st|su|sv|sy|sz|\
tc|td|tel|tf|tg|th|tj|tk|tl|tm|tn|to|tp|travel|tr|tt|tv|tw|tz|\
ua|ug|uk|um|us|uy|uz|\
va|vc|ve|vg|vi|vn|vu|\
wf|ws|\
ye|yt|yu|\
za|zm|zw\
)\
`),
        },

        bareLink: {
          match: new RegExp(`\
\
\
\
([^\
\\s\
\\x00-\\x2c\
\\x2e-\\x2f\
\\x3a-\\x40\
\\x5b-\\x60\
\\x7b-\\x7f\
]+\\.)+\
(?:tld)\
`),
        },

        autolink: {
          match: new RegExp(`\
^\
<\
(?:\
(email)\
|\
(url|bareLink)\
)\
>\
`),
          token(...args) {
            const [, email, url] = Array.from(args[0]);
            if (email != null) {
              return {
                type: 'mailto',
                email,
              };
            } else if (new RegExp(`^[\\w-]+:`).test(url)) {
              return {
                type: 'link',
                url,
              };
            } else {
              return {
                type: 'link',
                url: `http://${url}`,
                text: url,
              };
            }
          },
        },

        email: {
          match: new RegExp(`\
^\
[-a-z0-9\\+\\._'%]+@[a-z0-9-\\.]+\\.[a-z]{2,}\
`),
          token(...args) {
            const [email] = Array.from(args[0]);
            return {
              type: 'mailto',
              email,
            };
          },
        },

        inside: {
          // used in link and reflink
          match: new RegExp(`\
(?:\
\\[\
[^\\]\\[]*\
\\]\
|\
[^\\]\\[]\
|\
\\]\
(?=\
[^\\[]*\
\\]\
)\
)*\
`),
        },

        href: {
          // used in link
          match: new RegExp(`\
\\s*\
<?\
(\
(?:\
[^\\s\\(\\)]?\
(?:\
\\(\
[^\\s()<>]*\
\\)\
|\
\\(\
)?\
)+\
)\
>?\
(?:\
\\s+\
['"]\
([\\s\\S]*?)\
['"]\
)?\
\\s*\
`),
        },

        emailLink: {
          match: new RegExp(`\
^\
\\[\
(inside)\
\\]\
\\(\
(email)\
\\)\
`),
          token(...args) {
            const [, text, email] = Array.from(args[0]);
            return {
              type: 'mailto',
              email,
              text,
            };
          },
        },

        link: {
          match: new RegExp(`\
^\
\\[\
(inside)\
\\]\
\\(\
href\
\\)\
`),
          token(...args) {
            const [, text, url, title] = Array.from(args[0]),
              ranges = args[2];
            return _linkToken({ text, url, title, ranges });
          },
        },

        image: {
          match: new RegExp(`\
^\
(!)\
\\[\
(inside)\
\\]\
\\(\
href\
\\)\
`),
          token(...args) {
            const [, , text, url, title] = Array.from(args[0]),
              ranges = args[2];
            return _linkToken({ image: true, text, url, title, ranges });
          },
        },

        reflink: {
          match: new RegExp(`\
^\
(!?)\
\\[\
(inside)\
\\]\
\\s*\
\\[\
([^\\]]*)\
\\]\
`),
          token(...args) {
            // [fooUP][] is equivalent to [fooUP][fooup]
            let ref;
            const [, image, text, reference] = Array.from(args[0]),
              state = args[1],
              ranges = args[2];
            if (
              (ref =
                state.references != null
                  ? state.references.get(reference || text)
                  : undefined) == null
            ) {
              return false;
            } else {
              return _linkToken({
                image,
                text,
                url: ref.url,
                title: ref.title,
                ranges,
              });
            }
          },
        },

        nolink: {
          match: new RegExp(`\
^\
(!?)\
\\[\
(\
(?:\
\\[\
[^\\]]*\
\\]\
|\
[^\\[\\]]\
)*\
)\
\\]\
`),
          token(...args) {
            let ref;
            const [, image, text] = Array.from(args[0]),
              state = args[1],
              ranges = args[2];
            if (
              (ref =
                state.references != null
                  ? state.references.get(text)
                  : undefined) == null
            ) {
              return false;
            } else {
              return _linkToken({
                image,
                text,
                url: ref.url,
                title: ref.title,
                ranges,
              });
            }
          },
        },

        url: {
          whenAllowed: 'autolink',
          match: new RegExp(`\
^\
\
(\
(?:\
[\\w-]+://\
|\
www\\d{0,3}[.]\
|\
[a-z0-9.\\-]+[.][a-z]{2,4}/\
)\
(?:\
[^\\s()<>]\
|\
\\(\
[^\\s()<>]*\
\\)\
)+\
(?:\
\\(\
[^\\s()<>]*\
\\)\
|\
[^\\s\`!()\\[\\]{};:'".,<>?«»“”‘’]\
)\
|\
(?:bareLink)\\b\
)\
`),
          token(...args) {
            const [url] = Array.from(args[0]);
            const parts = new RegExp(`^([\\w-]+)://([\\s\\S]*)$`).exec(url);

            if (parts) {
              const [, protocol, rest] = Array.from(parts);
              const withLowerCaseProtocol = `${protocol.toLowerCase()}://${rest}`;
              if (withLowerCaseProtocol === url) {
                return {
                  type: 'link',
                  url: withLowerCaseProtocol,
                };
              } else {
                return {
                  type: 'link',
                  url: withLowerCaseProtocol,
                  text: url,
                };
              }
            } else {
              return {
                type: 'link',
                url: `http://${url}`,
                text: url,
              };
            }
          },
        },

        strong: {
          match: new RegExp(`\
^__([\\s\\S]+?)__(?!_)\
|\
^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)\
`),
          token(...args) {
            const [, underscored, starred] = Array.from(args[0]),
              state = args[1],
              ranges = args[2];
            const text = underscored != null ? underscored : starred;
            return [
              { type: 'strong_start' },
              ...Array.from(this.inlineLex(text, state, ranges.slice(2, text))),
              { type: 'strong_end' },
            ];
          },
        },

        em: {
          match: new RegExp(`\
\
^\\b_([\\s\\S]*?[^_])_(?!_)\\b\
|\
\
^\\*([\\s\\S]*?[^*])\\*(?!\\*)\
`),
          token(...args) {
            const [, underscored, starred] = Array.from(args[0]),
              state = args[1],
              ranges = args[2];
            const text = underscored != null ? underscored : starred;
            return [
              { type: 'em_start' },
              ...Array.from(this.inlineLex(text, state, ranges.slice(1, text))),
              { type: 'em_end' },
            ];
          },
        },

        strikethrough: {
          match: new RegExp(`\
\
^~~([\\s\\S]+?)~~\
`),
          token(...args) {
            const [, struckthrough] = Array.from(args[0]),
              state = args[1],
              ranges = args[2];
            const text = struckthrough;
            return [
              { type: 'strikethrough_start' },
              ...Array.from(this.inlineLex(text, state, ranges.slice(2, text))),
              { type: 'strikethrough_end' },
            ];
          },
        },

        code: {
          match: new RegExp(`\
^(\`+)\\s*((?:\\1\`+|[\\s\\S])+?)\\s*\\1(?!\`)\
\
\
\
`),
          token(...args) {
            const [, , code] = Array.from(args[0]);
            return {
              type: 'code',
              text: code,
            };
          },
        },

        break: {
          match: new RegExp(`\
^\\x20*\\n(?!\\s*$)\
\
`),
          token() {
            return { type: 'break' };
          },
        },

        atMention: {
          match: new RegExp(`\
^\
@\
([a-z0-9_]+)\
`),
          token(...args) {
            const [, username] = Array.from(args[0]);
            return {
              type: 'atMention',
              username,
            };
          },
        },

        emoji: {
          match: new RegExp(`\
^\
:([a-z0-9_+-:]+):\
`),
          token(...args) {
            const [, emoji] = Array.from(args[0]);
            return {
              type: 'emoji',
              emoji,
            };
          },
        },

        hashtag: {
          nondefault: true,
          match: new RegExp(`\
^\
\\#\
([\\S]+)\
`),
          token(...args) {
            const [all] = Array.from(args[0]);
            return {
              type: 'text', // for the moment, just print it back out normally
              text: all,
            };
          },
        },

        // matches 6 char hex color codes
        hexCode: {
          match: new RegExp(`\
\\#[a-fA-F0-9]{6}\
`),
        },

        // matches number from 0 - 255 inclusive
        hexNum: {
          match: new RegExp(`\
(?:25[0-5]|2[0-4]\\d|1?\\d{1,2})\
`),
        },

        // matches decimal percents like 0 or 1 or 0.33 etc.
        decimalPercent: {
          match: new RegExp(`\
(?:0|1(?:\\.0)?|0?\\.\\d+)\
`),
        },

        colorChip: {
          match: new RegExp(`\
^\
(\
hexCode\
|\
(?:rgb\\(hexNum,\\x20*hexNum,\\x20*hexNum\\))\
|\
(?:rgba\\((?:hexNum,\\x20*){3}decimalPercent\\))\
)\
(?:(?!\\w)|$)\
`),
          token(...args) {
            const [color] = Array.from(args[0]);
            return {
              type: 'colorChip',
              color,
            };
          },
        },

        text: {
          required: true,
          // We're trying to match everything we can, up to something that looks like
          // it might be the start of a different inline token
          match: new RegExp(`\
^\
[\\s\\S]+?\
(?:\
\\w[@\\#:][\\x20\\S]+?\
\
\
)?\
(?=\
[\\\\<!\\[_*\`~]\
|\
\\x20*\\n\
\
|\
[@:\\#]\
|\
(?:rgba?\\()\
|\
(?:\\b(?:url|email))\
|\
$\
)\
`),
          token(...args) {
            const [all] = Array.from(args[0]);
            return {
              type: 'text',
              text: all,
            };
          },
        },

        error: {
          required: true,
          match: /^[\s\S]+/,
          token(...args) {
            const [all] = Array.from(args[0]);
            throw Error(`invalid inline input ${all}`);
          },
        },
      };

      parseAtMention = function ({ username }) {
        if (this.options.lookupMember != null) {
          const [userFullName, isMe] = Array.from(
            this.options.lookupMember(username, this.state),
          );
          if (userFullName != null) {
            return this.html('span', `@${username}`, {
              attrs: {
                class: `atMention${isMe ? ' me' : ''}`,
                title: `${userFullName}`,
              },
            });
          }
        }
        return this.text(`@${username}`);
      };

      this.prototype.parseBlockOutput = {
        space() {
          return '';
        },
        hr() {
          return this.htmln('hr', null);
        },
        heading({ depth, children }) {
          return this.htmln(`h${depth}`, this.children(children));
        },
        blockquote_start() {
          return this.htmln('blockquote', this.process('blockquote_end'), {
            newlineAfterTag: true,
          });
        },
        list_start({ tag }) {
          return this.htmln(tag, this.process('list_end'), {
            newlineAfterTag: true,
          });
        },
        list_item_start({ condense }) {
          return this.htmln('li', this.process('list_item_end', condense));
        },
        text({ children }) {
          return this.htmln('p', this.children(children));
        },
        code({ text }) {
          return this.htmln('code', this.text(text), {
            preTag: '<pre>',
            postTag: '</pre>',
          });
        },
        atMention: parseAtMention,
      };

      this.prototype.parseInlineOutput = {
        text({ text }) {
          return this.text(text);
        },
        strong_start() {
          return this.html('strong', this.process('strong_end'));
        },
        em_start() {
          return this.html('em', this.process('em_end'));
        },
        strikethrough_start() {
          return this.html('del', this.process('strikethrough_end'));
        },
        code({ text }) {
          return this.html('code', this.escape(text));
        },
        break() {
          return this.html('br', null);
        },
        link({ url, text, title, children }) {
          const content =
            children != null
              ? this.children(children)
              : this.escape(text != null ? text : url);
          const shouldOpenInNewTab = this.options.shouldOpenLinkInNewTab(url);
          const target = shouldOpenInNewTab ? '_blank' : null;
          // Okay, story time for noreferrer:
          // https://wiki.whatwg.org/wiki/Links_to_Unrelated_Browsing_Contexts
          // This workaround only works around this stupid browser behavior in
          // Chrome and Firefox. Safari is still vulnerable. IE too, probably.
          // The Right Fix™ is to have a server-side redirect step, which we
          // might do one day.
          // nofollow is added to keep us from being a spammer target
          const rel = shouldOpenInNewTab ? 'noreferrer nofollow' : null;
          return this.html('a', content, {
            attrs: { href: url, title, target, rel },
          });
        },
        mailto({ email, text }) {
          return this.html('a', this.escape(text != null ? text : email), {
            attrs: { href: `mailto:${email}` },
          });
        },
        image({ url, title, text }) {
          return this.html('img', null, {
            attrs: { src: url, alt: text, title },
          });
        },
        atMention: parseAtMention,
        emoji({ emoji }) {
          const emojiResult =
            typeof this.options.lookupEmoji === 'function'
              ? this.options.lookupEmoji(emoji, this.state)
              : undefined;
          if (emojiResult && typeof emojiResult === 'object') {
            const { emojiUrl, emojiMarkup } = emojiResult;
            // if we have the entire markup, so we can just render as is
            if (emojiMarkup != null) {
              return emojiMarkup;
            } else if (emojiUrl != null) {
              return this.html('img', null, {
                attrs: { src: emojiUrl, title: emoji, class: 'emoji' },
              });
            }
          } else if (typeof emojiResult === 'string') {
            return this.html('img', null, {
              attrs: { src: emojiResult, title: emoji, class: 'emoji' },
            });
          } else {
            return this.text(`:${emoji}:`);
          }
        },
        colorChip({ color }) {
          const chipDiv = this.html('span', '', {
            attrs: {
              class: 'mkdwn-color-chip',
              style: `background-color:${color};`,
            },
          });
          return this.html('span', color.concat(chipDiv));
        },
      };

      this.prototype.parseBlockOutputText = {
        space() {
          return this.plaintextn('');
        },
        hr() {
          return this.plaintextn('');
        },
        heading({ depth, children }) {
          return this.plaintextn(this.textChildren(children));
        },
        blockquote_start() {
          return this.plaintext(this.textProcess('blockquote_end'));
        },
        list_start({ tag }) {
          return Array.from(this.textProcess('list_end').split('\n'))
            .map((line) => this.plaintextn(` ${line}`))
            .join('');
        },

        list_item_start({ tag, index, condense }) {
          const bullet = tag === 'ol' ? `${index + 1}.` : '*';
          return this.plaintextn(
            `${bullet} ${this.textProcess('list_item_end', condense)}`,
          );
        },
        text({ children }) {
          return this.plaintextn(`${this.textChildren(children)}\n`);
        },
        code({ text }) {
          return this.plaintextn(text);
        },
        atMention({ username }) {
          return this.plaintextn(username);
        },
      };

      this.prototype.parseInlineOutputText = {
        text({ text }) {
          return this.plaintext(text);
        },
        strong_start() {
          return this.plaintext(this.textProcess('strong_end'));
        },
        em_start() {
          return this.plaintext(this.textProcess('em_end'));
        },
        strikethrough_start() {
          return this.plaintext(
            '~~' + this.textProcess('strikethrough_end') + '~~',
          );
        },
        code({ text }) {
          return this.plaintext(text);
        },
        break() {
          return this.plaintext('\n');
        },
        link({ url, text, title, children }) {
          if (children != null) {
            return this.plaintext(`${this.textChildren(children)} (${url})`);
          } else if (text != null) {
            return this.plaintext(`${text} (${url})`);
          } else {
            return this.plaintext(url);
          }
        },
        mailto({ email, text }) {
          if (text != null) {
            return this.plaintext(`${text} (${email})`);
          } else {
            return this.plaintext(email);
          }
        },
        image({ url, title, text }) {
          if (title != null) {
            return this.plaintext(title);
          } else {
            return this.plaintext('');
          }
        },
        atMention({ username }) {
          return this.plaintext(username);
        },
        emoji({ emoji }) {
          return this.plaintext(`:${emoji}:`);
        },
        colorChip({ color }) {
          return this.plaintext(color);
        },
      };

      _prepareText = (text) =>
        text
          .replace(/\r\n|\r/g, '\n') // Get rid of any \r
          .replace(/\t/g, '    ') // Turn tabs into spaces
          .replace(/\u00a0/g, ' ') // Turn no-break spaces into plain old spaces
          .replace(/\u2424/g, '\n');
    }
    //takes in a list of options, and a method to locate the url/disklocation of an emoji
    constructor(options) {
      if (options == null) {
        options = {};
      }
      this.options = options;
      if (this.options.shouldOpenLinkInNewTab == null) {
        this.options.shouldOpenLinkInNewTab = (url) => true;
      }

      this.lexerBlockRules = this.options.inlineOnly
        ? [TrelloMarkdown.lexerBlockRules.error]
        : this._expandRules(
            TrelloMarkdown.lexerBlockRules,
            this.options.restrict != null
              ? this.options.restrict.block
              : undefined,
          );

      this.lexerInlineRules = this._expandRules(
        TrelloMarkdown.lexerInlineRules,
        this.options.restrict != null
          ? this.options.restrict.inline
          : undefined,
      );
    }

    _expandRules(rules, enabledRules) {
      // To save brainspace, we've allowed the rules to refer to each other
      // e.g.
      //
      // foo: /([a-z]+)/
      // bar: /([0-9]+)/
      // baz: /(foo|bar)/
      //
      // We need to expand the regexes to their full form, e.g.
      // baz: /(([a-z]+)|([0-9]+))

      // Sort the original rule names by length descending, to guarantee that we
      // don't match a name that's a substring of another name
      let ruleName, rule, name;
      const originalRuleNames = Object.keys(rules).sort(
        (a, b) => b.length - a.length,
      );
      const regexRuleName = new RegExp(`${originalRuleNames.join('|')}`, 'g');

      if (enabledRules != null) {
        // We expand the enabledRules to include rules that
        // - are required (e.g. the 'error' rule)
        // - only exist to be replacements inside other rules
        enabledRules = enabledRules.concat(
          (() => {
            const result = [];

            for (ruleName in rules) {
              rule = rules[ruleName];
              if (rule.required || rule.token == null) {
                result.push(ruleName);
              }
            }

            return result;
          })(),
        );
      } else {
        // enable all rules that are not specifically disabled by default
        enabledRules = (() => {
          const result1 = [];
          for (name in rules) {
            rule = rules[name];
            if (!(rule.nondefault != null ? rule.nondefault : false)) {
              result1.push(name);
            }
          }
          return result1;
        })();
      }

      // Filter out the rules that aren't enabled
      // ... but make sure that the entries stay in the same order they were in,
      // since the order of the rules is important
      rules = pick(rules, intersection(Object.keys(rules), enabledRules));

      var compile = (ruleName) => {
        // We need to make a copy of the rule, since it may compile differently
        // depending on which other rules are enabled
        const compiledRule = (rules[ruleName] = Object.assign(
          {},
          rules[ruleName],
        ));
        // Immediately mark this rule as compiled, so we can't have infinite
        // recursion
        compiledRule.compiled = true;

        const regexSource = compiledRule.match.source.replace(
          regexRuleName,
          function (replacementRuleName) {
            let replacement;
            const replacementRule = rules[replacementRuleName];

            if (
              (replacementRule != null ? replacementRule.match : undefined) !=
              null
            ) {
              if (!replacementRule.compiled) {
                compile(replacementRuleName);
              }
              replacement = replacementRule.match;
            } else {
              // We didn't find the replacement rule, because that rule was deleted
              // Let's fill the placeholder with something that we know won't match
              // anything
              // eslint-disable-next-line no-empty-character-class
              replacement = /[]/;
            }

            // Remove any ^ from the replacement, unless it's a [^...]
            return replacement.source.replace(
              new RegExp(`(^|[^\\[])\\^`, 'g'),
              '$1',
            );
          },
        );

        compiledRule.match = new RegExp(`${regexSource}`);
        compiledRule.match_i = new RegExp(`${regexSource}`, 'i');
        compiledRule.match_gim = new RegExp(`${regexSource}`, 'gim');
        return compiledRule;
      };

      for (ruleName in rules) {
        const { match, compiled } = rules[ruleName];
        if (match != null && !compiled) {
          compile(ruleName);
        }
      }

      return rules;
    }

    _disallow(state, ...disallowed) {
      state = Object.assign({}, state);
      state.disallowed = (
        state.disallowed != null ? state.disallowed : []
      ).concat(disallowed);
      return state;
    }

    // Tokenize the text
    lex(rules, text, state, ranges) {
      if (state == null) {
        state = {};
      }
      if (state.locations == null) {
        state.locations = [];
      }

      // Get rid of lines containing only spaces
      const rangesOrig = ranges.clone();
      text = text.replace(
        new RegExp(`^\\x20+$`, 'gm'),
        function (match, index) {
          ranges = ranges.subtract(rangesOrig.slice(index, match));
          return '';
        },
      );

      const allTokens = [];
      let index = 0;

      while (text) {
        for (let rule in rules) {
          // See if our current input matches the rule
          // (Some block elements, e.g. a "def" should only match if we haven't
          // recursed at all.  For these, we check rule.top vs state.top)
          const { match_i, token, whenAllowed } = rules[rule];
          if (token != null) {
            var capture;

            if (
              whenAllowed != null &&
              state.disallowed != null &&
              Array.from(state.disallowed).includes(whenAllowed)
            ) {
              continue;
            }

            if ((capture = match_i.exec(text)) != null) {
              const all = capture[0];
              const tokenRanges = ranges.slice(index, all);

              let ruleTokens = token.call(this, capture, state, tokenRanges);
              if (ruleTokens === false) {
                // Matched the regex, but isn't being considered match (e.g. a link
                // reference, where the reference isn't defined)
                continue;
              }

              if (ruleTokens != null) {
                if (!Array.isArray(ruleTokens)) {
                  ruleTokens = [ruleTokens];
                }

                for (let t of Array.from(ruleTokens)) {
                  allTokens.push(t);
                }
              }

              // Skip the text that matched
              if (all.length === 0) {
                throw Error('infinite loop');
              }
              text = text.substr(all.length);

              for (let [start, stop] of Array.from(tokenRanges.spans)) {
                state.locations.push({ start, stop, rule });
              }

              index += all.length;

              break;
            }
          }
        }
      }
      return allTokens;
    }

    _expandChildren(tokens, state, condense) {
      let processedTokens, token;
      if (tokens.length === 0) {
        return;
      }

      if (condense) {
        // If we have any consecutive text blocks, or text blocks separated by
        // whitespace, combine them
        let [lastToken, ...rest] = Array.from(tokens);
        processedTokens = [lastToken];

        const hasType = (token, type) =>
          token.canCondense && token.children != null && token.type === type;

        for (let index = 0; index < rest.length; index++) {
          token = rest[index];
          if (
            hasType(lastToken, 'text') &&
            (hasType(token, 'text') ||
              (hasType(token, 'space') && hasType(rest[index + 1], 'text')))
          ) {
            lastToken.children = {
              text: lastToken.children.text + token.children.text,
              ranges: new SelectionRange([
                ...Array.from(lastToken.children.ranges.spans),
                ...Array.from(token.children.ranges.spans),
              ]),
            };
          } else {
            processedTokens.push(token);
            lastToken = token;
          }
        }
      } else {
        processedTokens = tokens;
      }

      for (token of Array.from(processedTokens)) {
        if (token.children != null) {
          const { text, ranges } = token.children;
          const childrenState =
            token.type === 'link' ? this._disallow(state, 'autolink') : state;
          const children = this.inlineLex(text, childrenState, ranges);
          this._expandChildren(children, childrenState);
          token.children = children;
        }
      }
    }

    blockLex(text, state, ranges, expandChildren) {
      if (ranges == null) {
        ranges = SelectionRange.fromString(text);
      }
      if (state.references == null) {
        state.references = {
          map: {},
          set(key, data) {
            return (this.map[key.toLowerCase()] = data);
          },
          get(key) {
            return this.map[key.toLowerCase()];
          },
        };
      }

      const tokens = this.lex(this.lexerBlockRules, text, state, ranges);
      if (expandChildren) {
        this._expandChildren(tokens, state, true);
      }
      return tokens;
    }

    inlineLex(text, state, ranges, expandChildren) {
      if (ranges == null) {
        ranges = SelectionRange.fromString(text);
      }
      const tokens = this.lex(this.lexerInlineRules, text, state, ranges);
      if (expandChildren) {
        this._expandChildren(tokens, state, true);
      }
      return tokens;
    }

    parse(rules, tokens, state) {
      // outputterContext is the "this" that the outputters get called with
      var outputterContext = {
        options: this.options,
        state,
        index: 0,
        next() {
          return (this.current = tokens[this.index++]);
        },
        process(stopType, condenseText) {
          // Go until we've run out of tokens, or consumed the stopType token
          const output = (() => {
            let token;
            const result = [];
            while ((token = this.next()) != null && token.type !== stopType) {
              if (condenseText && token.type === 'text') {
                result.push(outputterContext.children(token.children));
              } else {
                const outputter = rules[token.type];
                if (outputter != null) {
                  result.push(outputter.call(outputterContext, token));
                } else {
                  throw Error(`invalid token type ${token.type}`);
                }
              }
            }
            return result;
          })();

          return output.join('');
        },

        textProcess(stopType, condenseText) {
          // Go until we've run out of tokens, or consumed the stopType token
          const output = (() => {
            let token;
            const result = [];
            while ((token = this.next()) != null && token.type !== stopType) {
              if (condenseText && token.type === 'text') {
                result.push(outputterContext.textChildren(token.children));
              } else {
                const outputter = rules[token.type];
                if (outputter != null) {
                  result.push(outputter.call(outputterContext, token));
                } else {
                  throw Error(`invalid token type ${token.type}`);
                }
              }
            }
            return result;
          })();

          return output.join('');
        },

        children: (tokens, text) => {
          return this.parseInline(tokens, state);
        },

        textChildren: (tokens, text) => {
          return this.parseInlineText(tokens, state);
        },

        escape(text) {
          if (text == null) {
            text = 'undefined';
          }
          return text
            .replace(/&/g, '&amp;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;');
        },

        safeUrl(url) {
          if (new RegExp(`^/`).test(url)) {
            return url;
          } else if (new RegExp(`^[^/]*:`).test(url)) {
            return url.replace(/^[^:]*/, function (protocol) {
              protocol = protocol.toLowerCase().replace(/[^\w-]/g, '');
              // We're not doing javascript: links, ever
              // Disallow data URIs as well; most browsers block anything bad
              // you could do with them, but we had at least one browser run
              // the link in our domain
              if (!protocol || /script|data/.test(protocol)) {
                return 'http';
                // mailto: are potentially dangerous, e.g. if they contain URL
                // parameters like attach; Only simple email adresses and the
                // subject and body parameters are supported
              } else if (
                /mailto/.test(protocol) &&
                !/^mailto:([-\w+._'%]+@[\w-.]+\.[a-z]{2,}[;]*)+((\?|&)(subject|body)=[^&]*)*?$/.test(
                  url,
                )
              ) {
                return 'invalid-mailto';
              } else {
                return protocol;
              }
            });
          } else {
            return `http://${url}`;
          }
        },

        text(text) {
          return this.escape(text);
        },

        plaintext(text) {
          return text;
        },

        plaintextn(text) {
          return this.plaintext(text) + '\n';
        },

        html(tag, content, param) {
          if (param == null) {
            param = {};
          }
          const { attrs, newlineAfterTag, preTag, postTag } = param;
          let output = '';
          if (preTag != null) {
            output += preTag;
          }
          output += `<${tag}`;

          if (attrs != null) {
            for (let name in attrs) {
              let value = attrs[name];
              if (value != null) {
                if (['src', 'href'].includes(name)) {
                  value = this.safeUrl(value);
                }
                output +=
                  ' ' +
                  `\
${name}="${this.escape(value)}"\
`;
              }
            }
          }
          output += '>';
          if (newlineAfterTag) {
            output += '\n';
          }
          if (content != null) {
            output += content + `</${tag}>`;
            if (postTag != null) {
              output += postTag;
            }
          }
          return output;
        },

        htmln(...args) {
          return this.html(...Array.from(args || [])) + '\n';
        },
      };

      return outputterContext.process();
    }

    parseBlocks(blockTokens, state) {
      if (state == null) {
        state = {};
      }
      return this.parse(this.parseBlockOutput, blockTokens, state);
    }

    parseInline(inlineTokens, state) {
      if (state == null) {
        state = {};
      }
      return this.parse(this.parseInlineOutput, inlineTokens, state);
    }

    parseBlocksText(blockTokens, state) {
      if (state == null) {
        state = {};
      }
      return this.parse(this.parseBlockOutputText, blockTokens, state);
    }

    parseInlineText(inlineTokens, state) {
      if (state == null) {
        state = {};
      }
      return this.parse(this.parseInlineOutputText, inlineTokens, state); // Turn the "symbol for a newline" into an actual
    }
    // newline

    format(text, state) {
      if (state == null) {
        state = {};
      }
      text = _prepareText(text);
      const output = (() => {
        if (this.options.inlineOnly) {
          return this.formatInline(text, state);
        } else {
          const tokens = this.blockLex(text, state, null, true);
          return this.parseBlocks(tokens, state);
        }
      })();

      return { output, locations: state.locations };
    }

    formatInline(text, state, ranges = null) {
      if (state == null) {
        state = {};
      }
      return this.parseInline(this.inlineLex(text, state, ranges, true), state);
    }

    text(text, state) {
      if (state == null) {
        state = {};
      }
      text = _prepareText(text);
      let output = (() => {
        if (this.options.inlineOnly) {
          return this.textInline(text, state);
        } else {
          const tokens = this.blockLex(text, state, null, true);
          return this.parseBlocksText(tokens, state);
        }
      })();

      output = output
        .replace(/^\s*|\s*$/g, '')
        .replace(/\n(\x20*\n)+/g, '\n\n');

      return { output, locations: state.locations };
    }

    textInline(text, state, ranges = null) {
      if (state == null) {
        state = {};
      }
      return this.parseInlineText(
        this.inlineLex(text, state, ranges, true),
        state,
      );
    }

    analyze(text, state) {
      if (state == null) {
        state = {};
      }
      text = _prepareText(text);

      if (this.options.inlineOnly) {
        this.inlineLex(text, state);
      } else {
        this.blockLex(text, state, null, true);
      }

      return state.locations;
    }
    // In a string containing markdown, get all the matches for the given set of rules
    // If you pass it a fxset (mapping rules to functions), it will apply the specified
    // function to each output
    getMatches(text, rules, fxSet) {
      let rule;
      if (fxSet == null) {
        fxSet = {};
      }
      const locations = this.analyze(text);
      const res = {};
      for (rule in rules) {
        res[rule] = [];
      }
      for (let item of Array.from(locations)) {
        if (item.rule in rules) {
          const matchtext = text.slice(item.start, item.stop);
          const output = !(item.rule in fxSet)
            ? matchtext
            : fxSet[item.rule](matchtext);
          res[item.rule].push(output);
        }
      }
      return res;
    }
    // In a string containing markdown, replace the sections of text that match
    // one of a set of rules
    replace(text, rules, fxReplace) {
      // We want to go in reverse so the replacements don't interfere with
      // the other locations
      const locations = this.analyze(text).sort((a, b) => b.start - a.start);

      // Keep track of the last index of the input that we've touched, so we
      // can guarantee that we don't try to modify a region that's already been
      // shifted (Theoretically you could provide rules that have locations that
      // overlap, e.g. an atMention and the paragraph that contains it)
      let offsetModified = text.length;

      let output = text;

      for (let { rule, start, stop } of Array.from(locations)) {
        if (Array.from(rules).includes(rule) && stop <= offsetModified) {
          output = [
            output.slice(0, start),
            fxReplace(output.slice(start, stop), {
              rule,
              options: this.options,
            }),
            output.slice(stop),
          ].join('');
          offsetModified = start;
        }
      }

      return output;
    }
  };
  TrelloMarkdown.initClass();
  return TrelloMarkdown;
})();

/*
A "SelectionRange" represents the sections of the original markdown input that
are currently being operated on

The impetus for having something like this is to be able to identify where in
a markdown string certain types of tokens (e.g. @mentions)
exist (Because of code blocks, escaping, and other contexts, it'd be very
difficult to do this with simple regular expressions)

A selection range can include multiple sections of text, which is necessary when
you have an input string like this:

"> test\n> @mention\n> test"
   ^^^^^^  ^^^^^^^^    ^^^^

The ^ denote the parts of the string that are being operated on when lexing the
paragraph that is "inside" the block quote; the sections aren't contiguous, and
is represented by 3 spans, 2-7, 9-18, 20-24

By the time the "paragraph" rule is reached, it's operating on a string that
looks like this:

"test\n@mention\ntest"

... and if we don't know which sections of the original source we're operating
on, we won't be able to report where the @mention occurs
*/
var SelectionRange = (function () {
  let _subtract = undefined;
  let _convertSubToSource = undefined;
  let _slice = undefined;
  SelectionRange = class SelectionRange {
    static initClass() {
      // Helper for the @subtract function
      _subtract = function (spansOriginal, subSpans) {
        const newSpans = [];

        const spans = Array.from(spansOriginal);

        let subIndex = 0;
        while (spans.length) {
          const nextSpan = spans.shift();
          if (subIndex >= subSpans.length) {
            // There's nothing left to subtract
            newSpans.push(nextSpan);
          } else {
            const [spanStart, spanEnd] = Array.from(nextSpan);
            const [subStart, subEnd] = Array.from(subSpans[subIndex]);

            if (subEnd <= spanStart) {
              // The subtraction comes completely before this span
              spans.unshift(nextSpan);
              subIndex++;
            } else if (subStart >= spanEnd) {
              // The subtraction comes completely after this span
              newSpans.push(nextSpan);
            } else if (subStart <= spanStart && subEnd < spanEnd) {
              // Clip the beginning of the span and put it back on the stack
              spans.unshift([subEnd, spanEnd]);
              subIndex++;
            } else if (subStart <= spanStart && subEnd >= spanEnd) {
              // Removes the whole span
            } else if (subStart > spanStart && subEnd < spanEnd) {
              // Chops the span in two
              newSpans.push([spanStart, subStart]);
              spans.unshift([subEnd, spanEnd]);
              subIndex++;
            } else if (subStart > spanStart && subEnd >= spanEnd) {
              // Chops the end off the span
              newSpans.push([spanStart, subStart]);
            }
          }
        }

        return newSpans;
      };

      // A selection range represents the locations of several ranges of characters
      // in a source string (S_source) that make up a substring (S_sub)
      //
      // This function converts a position in S_sub to the equivalent position in
      // S_source
      //
      // For example:
      //
      // S_source:    a b c d e f g h i
      // Positions:  0 1 2 3 4 5 6 7 8 9
      //                           |
      // Spans:        [     ]   [ | ]      (i.e. [ [1,4], [6,8] ])
      //                           |
      // S_sub:         b c d     g|h
      // Positions:    0 1 2 3     4 5      (3 is ambiguous, but we map it to 4)
      //
      // Converting 4 from positionSub to a positionSource yields 7
      _convertSubToSource = function (spans, positionSub) {
        for (let [startSource, stopSource] of Array.from(spans)) {
          const spanLength = stopSource - startSource;
          if (positionSub <= spanLength) {
            return startSource + positionSub;
          } else {
            positionSub -= spanLength;
          }
        }

        throw Error('invalid position');
      };

      _slice = function (spans, startSub, stopSub) {
        const startSource = _convertSubToSource(spans, startSub);
        const stopSource = _convertSubToSource(spans, stopSub);

        const spanBeforeStart = [0, startSource];
        const spanAfterStop = [stopSource, spans[spans.length - 1][1]];

        return _subtract(spans, [spanBeforeStart, spanAfterStop]);
      };
    }
    constructor(spans) {
      if (spans == null) {
        spans = [];
      }
      this.spans = spans;
    }

    static fromString(s) {
      return new SelectionRange([[0, s.length]]);
    }

    clone() {
      return new SelectionRange(Array.from(this.spans));
    }

    // Remove the characters in one selection range from this one
    //
    // e.g.
    //
    // Original String:               abcdefghijklmnopqrstuvwxyz
    // Current Selection Range:     -  bcdefghij   nopqrs    xy
    // Selection Range to Subtract:     cde      lmno  rstu wxyz
    //                                ---------------------------
    // Result:                         b   fghij     pq
    subtract(range) {
      return new SelectionRange(_subtract(this.spans, range.spans));
    }

    // Given the start/stop positions in the substring, return the selection range
    // on the original string that describes the locations in the original string
    // of the the characters in substring.slice(start, stop)
    //
    // Using the example from above, slice(1, 4) would return a selection range
    // with spans [2, 4] and [6, 7]
    slice(startSub, stopSubOrString) {
      if (typeof stopSubOrString === 'string') {
        return this.slice(startSub, startSub + stopSubOrString.length);
      }

      return new SelectionRange(_slice(this.spans, startSub, stopSubOrString));
    }
  };
  SelectionRange.initClass();
  return SelectionRange;
})();

module.exports = TrelloMarkdown;
