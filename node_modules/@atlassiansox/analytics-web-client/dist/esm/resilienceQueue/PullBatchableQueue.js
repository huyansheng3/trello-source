import Scheduler from '../analytics.js-integration-segmentio/Scheduler';
import ResilienceDb, { CallbackProcessingErrorName } from '../resiliencedb';
import getMetricsCollector from './Metrics';
import { ResilienceMechanism } from './types';
const ONE_MINUTE = 60000;
const LONG_POLLING_OPTIONS = {
  backoffFactor: 0,
  backoffJitter: 0,
  flushWaitMs: ONE_MINUTE,
  minRetryDelay: ONE_MINUTE,
  maxRetryDelay: ONE_MINUTE
};
const DEFAULT_POLLING_OPTIONS = {
  backoffFactor: 2,
  backoffJitter: 10,
  batchFlushSize: 7,
  flushBeforeUnload: false,
  flushWaitMs: 500,
  // TODO figure out this number. For indexeddb we are sharing the queue with all tabs
  maxItems: 1000,
  maxRetryDelay: 30000,
  minRetryDelay: 1000,
  resilienceMechanism: ResilienceMechanism.INDEXEDDB
};
export default class PullBatchableQueue {
  constructor(flushCallback, product, options) {
    this.resilience = new ResilienceDb(product);
    this.batchFlushCallback = flushCallback;
    this.options = this.buildOptions(options);
    this.scheduler = new Scheduler(this.options, this.scheduleCallback.bind(this));
    this.longPollingScheduler = new Scheduler(LONG_POLLING_OPTIONS, this.scheduleLongCallBack.bind(this));
    this.metricsCollector = getMetricsCollector();
    this.metricsCollector.setResilienceMechanism(ResilienceMechanism.INDEXEDDB);
  }

  start() {
    this.longPollingScheduler.schedule();
  }

  stop() {
    this.scheduler.stop();
    this.longPollingScheduler.stop();
  }

  addItem(item) {
    this.resilience.addItem(item);
    this.scheduler.schedule();
    this.metricsCollector.addToEventCount();
  }

  getGlobalRetryCount() {
    return this.scheduler.getFailureCount();
  }

  async scheduleCallback(done) {
    try {
      await this.resilience.processItems(this.flush.bind(this), this.options.batchFlushSize);
    } catch (error) {
      if ((error === null || error === void 0 ? void 0 : error.name) === CallbackProcessingErrorName) {
        done(error);
        return;
      } // TODO we can probably log here but throwing is useless as it will just be shallowed by the Scheduler
      // In theory something else should catch all other errors from indexeddb and this should never happen.

    } finally {
      await this.checkEventCountAndReschedule();
    }

    done();
  }

  async checkEventCountAndReschedule() {
    const eventWaitingCount = await this.resilience.getItemCount();

    if (eventWaitingCount > 0) {
      this.scheduler.schedule({
        immediate: eventWaitingCount >= this.options.batchFlushSize
      });
    }
  }

  async scheduleLongCallBack(done) {
    // Eventually we will want to recover events from localstorage too
    // We dont want to flush events from here as there maybe issues with analytics-service
    // Scheduler has all the context and can schedule the next batch accordingly
    await this.checkEventCountAndReschedule();
    done();
    this.longPollingScheduler.schedule();
  }

  flush(wrappedItems) {
    return new Promise((resolve, reject) => {
      if (wrappedItems.length <= 0) {
        resolve();
        return;
      }

      const items = wrappedItems.map(w => w.item);
      this.batchFlushCallback(items, error => {
        if (error) {
          reject(error);
        } else {
          resolve();
        }
      });
    });
  }

  buildOptions(options) {
    return {
      backoffFactor: options.backoffFactor || DEFAULT_POLLING_OPTIONS.backoffFactor,
      backoffJitter: options.backoffJitter !== undefined ? options.backoffJitter : DEFAULT_POLLING_OPTIONS.backoffJitter,
      batchFlushSize: options.batchFlushSize || DEFAULT_POLLING_OPTIONS.batchFlushSize,
      flushBeforeUnload: options.flushBeforeUnload || DEFAULT_POLLING_OPTIONS.flushBeforeUnload,
      flushWaitMs: options.flushWaitMs || DEFAULT_POLLING_OPTIONS.flushWaitMs,
      maxItems: options.maxItems || DEFAULT_POLLING_OPTIONS.maxItems,
      maxRetryDelay: options.maxRetryDelay || DEFAULT_POLLING_OPTIONS.maxRetryDelay,
      minRetryDelay: options.minRetryDelay || DEFAULT_POLLING_OPTIONS.minRetryDelay,
      resilienceMechanism: DEFAULT_POLLING_OPTIONS.resilienceMechanism
    };
  }

}